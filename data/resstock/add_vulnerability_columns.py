"""Add vulnerability indicator columns to ResStock metadata.

Adds boolean columns for EAP tier assignment: has_child_under_6,
has_person_over_60, has_disabled_person, and a composite is_vulnerable.

Current implementation: assigns random values using a fixed seed for
reproducibility. A future issue will replace this with conditional
probability estimates from ACS PUMS microdata (share of low-income
households with each vulnerable member type, by PUMA).

Same CLI pattern as identify_hp_customers.py and identify_heating_type.py.
"""

from __future__ import annotations

import argparse
from typing import cast

import numpy as np
import polars as pl
from cloudpathlib import S3Path

from utils import get_aws_region

STORAGE_OPTIONS = {"aws_region": get_aws_region()}

# ACS-derived approximate rates for low-income HHs (placeholder values).
# TODO: Replace with real PUMS-derived conditional probabilities by PUMA
# once the PUMS pipeline from RDP-93 is integrated. These rates are rough
# national averages for illustration only.
_DEFAULT_RATE_CHILD_UNDER_6 = 0.20
_DEFAULT_RATE_PERSON_OVER_60 = 0.35
_DEFAULT_RATE_DISABLED = 0.15


def add_vulnerability_columns(
    metadata: pl.LazyFrame,
    *,
    seed: int = 42,
    rate_child_under_6: float = _DEFAULT_RATE_CHILD_UNDER_6,
    rate_person_over_60: float = _DEFAULT_RATE_PERSON_OVER_60,
    rate_disabled: float = _DEFAULT_RATE_DISABLED,
) -> pl.LazyFrame:
    """Add vulnerability boolean columns to metadata.

    Adds: has_child_under_6, has_person_over_60, has_disabled_person,
    is_vulnerable (any of the three).

    Current approach: random assignment using fixed seed. Each building
    independently gets True/False for each indicator at the given rates.
    """
    # Collect bldg_ids to generate deterministic random assignments
    bldg_ids = cast(pl.DataFrame, metadata.select("bldg_id").collect())["bldg_id"]
    n = bldg_ids.len()

    rng = np.random.default_rng(seed)
    child_flags = rng.random(n) < rate_child_under_6
    elder_flags = rng.random(n) < rate_person_over_60
    disabled_flags = rng.random(n) < rate_disabled
    vulnerable_flags = child_flags | elder_flags | disabled_flags

    vuln_df = pl.DataFrame(
        {
            "bldg_id": bldg_ids,
            "has_child_under_6": child_flags,
            "has_person_over_60": elder_flags,
            "has_disabled_person": disabled_flags,
            "is_vulnerable": vulnerable_flags,
        }
    ).lazy()

    # Drop pre-existing vulnerability columns so re-runs don't create duplicates
    vuln_cols = [
        "has_child_under_6",
        "has_person_over_60",
        "has_disabled_person",
        "is_vulnerable",
    ]
    existing = [c for c in vuln_cols if c in metadata.collect_schema().names()]
    if existing:
        metadata = metadata.drop(existing)

    return metadata.join(vuln_df, on="bldg_id", how="left")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Add vulnerability columns to ResStock metadata."
    )
    parser.add_argument(
        "--input_dir",
        required=True,
        help="Full S3Path url pointing to the input metadata file directory",
    )
    parser.add_argument(
        "--output_dir",
        required=True,
        help="Full S3Path url pointing to the output directory",
    )
    parser.add_argument(
        "--input_filename",
        required=True,
        help="Input filename (e.g. 'metadata-sb.parquet')",
    )
    parser.add_argument(
        "--output_filename",
        required=True,
        help="Output filename (e.g. 'metadata-sb.parquet')",
    )
    parser.add_argument(
        "--upgrade_id",
        required=True,
        help="Upgrade id (e.g. '00')",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="RNG seed for random vulnerability assignment",
    )
    args = parser.parse_args()

    metadata_path = S3Path(args.input_dir) / args.input_filename
    if not metadata_path.exists():
        raise FileNotFoundError(f"Metadata file {metadata_path} does not exist")
    input_metadata = pl.scan_parquet(
        str(metadata_path), storage_options=STORAGE_OPTIONS
    )

    output_metadata = add_vulnerability_columns(input_metadata, seed=args.seed)

    output_path = S3Path(args.output_dir) / args.output_filename
    if not output_path.parent.exists():
        output_path.parent.mkdir(parents=True)
    output_metadata.sink_parquet(str(output_path), storage_options=STORAGE_OPTIONS)
    print(f"Added vulnerability columns and wrote metadata to {output_path}")
